{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9d93d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_error\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d090e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('monthly_FRED-MD_2024-12_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1e47c1",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e22b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_LAGS = 20\n",
    "TRAIN_RATIO = 0.8\n",
    "HIDDEN_DIM = 16\n",
    "NUM_LAYERS = 1\n",
    "DROPOUT = 0.0\n",
    "LR = 3e-4\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "CLASS_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4cb8ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a9fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only numeric features (drop target)\n",
    "numeric = df.select_dtypes(include=[np.number]).copy()\n",
    "X_all = numeric.drop(columns=[\"sign\", \"volatility\"]).values\n",
    "y_vola = numeric[\"volatility\"].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14b0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sliding-window sequences\n",
    "def create_sequences(X, y_vola, window):\n",
    "    Xs, yv = [], []\n",
    "    for i in range(window, len(X)):\n",
    "        Xs.append(X[i - window : i, :])\n",
    "        yv.append(y_vola[i])\n",
    "    return np.array(Xs), np.array(yv)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_all, y_vola, NUMBER_OF_LAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4e322f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(X_seq) * TRAIN_RATIO)\n",
    "X_train = X_seq[:train_size]; X_test = X_seq[train_size:]\n",
    "yv_train = y_seq[:train_size]; yv_test = y_seq[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c2caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch datasets\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "yv_train_t = torch.tensor(yv_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, yv_train_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55862638",
   "metadata": {},
   "source": [
    "## Define LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6159de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=16, num_layers=1, dropout=0.0):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        return self.fc(out)\n",
    "\n",
    "input_dim = X_train.shape[2]\n",
    "model = SimpleLSTM(input_dim=input_dim, hidden_dim=HIDDEN_DIM, num_layers=NUM_LAYERS, dropout=DROPOUT)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb86a56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleLSTM(\n",
       "  (lstm): LSTM(113, 16, batch_first=True)\n",
       "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f0b773",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08cdf2",
   "metadata": {},
   "source": [
    "X_train_t contains batch size, sequence length (number of lags) and number of variables.\n",
    "Pytorch automatically calls forward()-method when input is given to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5a311ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 2534.4175\n",
      "Epoch 10: loss = 2488.8174\n",
      "Epoch 20: loss = 2437.8862\n",
      "Epoch 30: loss = 2380.7739\n",
      "Epoch 40: loss = 2312.1919\n",
      "Epoch 50: loss = 2244.0337\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(EPOCHS+1):     # number of seeing the training data for learning parameters\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8125a42c",
   "metadata": {},
   "source": [
    "### Out of sample Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cff9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    vol_preds = model(X_test_t).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90bdf812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volatility MSE (original units): 1013.103882\n",
      "Volatility RMSE (original units): 31.829292\n",
      "Volatility MAE (original units): 30.366154\n"
     ]
    }
   ],
   "source": [
    "# regression metrics for volatility\n",
    "mse_vol = mean_squared_error(yv_test, vol_preds)\n",
    "rmse_vol = root_mean_squared_error(yv_test, vol_preds)\n",
    "mae = mean_absolute_error(yv_test, vol_preds)\n",
    "print(f\"Volatility MSE (original units): {mse_vol:.6f}\")\n",
    "print(f\"Volatility RMSE (original units): {rmse_vol:.6f}\")\n",
    "print(f\"Volatility MAE (original units): {mae:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcaf0eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 8,401 | Trainable params: 8,401\n",
      "Data points: 90735\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(m):\n",
    "    total = sum(p.numel() for p in m.parameters())\n",
    "    trainable = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "    print(f\"Total params: {total:,} | Trainable params: {trainable:,}\")\n",
    "\n",
    "count_parameters(model)\n",
    "\n",
    "print(f\"Data points: {df.shape[0]*df.shape[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
